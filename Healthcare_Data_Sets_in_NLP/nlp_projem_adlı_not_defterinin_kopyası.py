# -*- coding: utf-8 -*-
"""NLP_projem adlı not defterinin kopyası

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WAQzJPhOLiBdv95s-gjaHo_qKifH_W-M
"""

!pip install pandas
!pip install numpy

# Gerekli kütüphaneleri yükleme
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

data = pd.read_csv('healthcare_dataset.csv')

data.head()

""" erkekler ve kadınları filtreleyeceğim"""

Male = data[data['Gender'] == 'Male']

Female = data[data['Gender'] == 'Female']

print('Male')
print(Male)

print('Female')
print(Female)

# Gender sütunundaki benzersiz değerleri kontrol et
unique_genders = data['Gender'].unique()
print("Benzersiz Gender değerleri:")
print(unique_genders)

# Eksik değerlerin olup olmadığını kontrol et
print(data.isnull().sum())

# Her sütunun veri türlerini kontrol et
print(data.dtypes)

# Yaş sütununda mantıksız değer olup olmadığını kontrol et
print(data[data['Age'] < 0])  # Negatif yaşları kontrol et
print(data[data['Age'] > 120])  # Çok yüksek yaşları kontrol et

data['Name'] = data['Name'].str.upper()

print(data['Name'].head())

data.dropna()
#print(data.dropna())
print(data.isna())

data['Name'] = data['Name'].str.lower()

print(data['Name'].head())

# Veriyi CSV dosyasına kaydet
data.to_csv('healthcare_dataset.csv', index=False)

# Yaşa göre küçükten büyüğe sıralama
data_sorted = data.sort_values(by='Age')


# Sıralanmış veriyi göster
print(data_sorted.head())

data_sorted = data.sort_values(by='Age', ascending=False)

print(data_sorted.head())

#Veriyi kaydetmek için

data.to_csv('healthcare_dataset.csv', index=False)

"""
**kalın metin** Veri Setini Sınıflandıracağım.
1.   Liste öğesi Veriyi geuplayacağım, sayılarını karşılaştıracğım
2.   Liste öğesi

"""

""" # Hastalıklara göre gruplama ve her hastalık için hasta sayısını göster"""
disease_groups = data.groupby('Medical Condition').size()

print(disease_groups)

#Hastalıklara göre gruplama ve yaşların ortalamasını hesaplama

disease_age_mean = data.groupby('Medical Condition')['Age'].mean()

print(disease_age_mean)

data.head()

# Hastalıklara göre gruplama ve yaşların ortalamasını hesapla
disease_age_mean = data.groupby('Medical Condition')['Age'].mean()

# Sonucu ekrana yazdır
print(disease_age_mean)

# Hastalıklara göre gruplama ve çeşitli sütunlar için özet istatistikler alma
disease_summary = data.groupby('Medical Condition').agg({
    'Age': ['mean', 'min', 'max'],
    'Billing Amount': ['sum', 'mean'],
    'Gender': 'count'
})

# Sonucu ekrana yazdır
print(disease_summary)

data.to_csv('healthcare_dataset.csv',index=False)

data.head()

# Cinsiyete göre hastalık dağılımı
gender_disease_distribution = data.groupby(['Medical Condition', 'Gender']).size().unstack()

# Sonucu ekrana yazdır
print(gender_disease_distribution)

# Hastalıklara göre ortalama fatura miktarı
disease_billing = data.groupby('Medical Condition')['Billing Amount'].mean()

# Sonucu ekrana yazdır
print(disease_billing)

#Hastalıklara Göre Yaş Dağılımı
# Hastalıklara göre yaş dağılımı
age_disease_distribution = data.groupby('Medical Condition')['Age'].describe()

# Sonucu ekrana yazdır
print(age_disease_distribution)

# Hastanelere göre hastalık dağılımı
hospital_disease_distribution = data.groupby(['Hospital', 'Medical Condition']).size().unstack()

# Sonucu ekrana yazdır
print(hospital_disease_distribution)

import matplotlib.pyplot as plt

# Hastalıkların bar grafiği
disease_groups.plot(kind='bar', figsize=(15, 6))
plt.title('Hastalıklara Göre Hasta Sayısı')
plt.xlabel('Hastalıklar')
plt.ylabel('Hasta Sayısı')
plt.show()

# Yaş ve fatura miktarı arasındaki korelasyon
age_billing_correlation = data['Age'].corr(data['Billing Amount'])

print("Yaş ve fatura miktarı arasındaki korelasyon: ", age_billing_correlation)

# Tedavi sürelerini hesaplama
data['Admission Date'] = pd.to_datetime(data['Date of Admission'])
data['Discharge Date'] = pd.to_datetime(data['Discharge Date'])
data['Treatment Duration'] = (data['Discharge Date'] - data['Admission Date']).dt.days

# Hastalıklara göre tedavi sürelerini inceleme
treatment_duration = data.groupby('Medical Condition')['Treatment Duration'].mean()

print(treatment_duration)

# Cinsiyete göre tedavi süresi
gender_treatment_duration = data.groupby(['Medical Condition', 'Gender'])['Treatment Duration'].mean()

print(gender_treatment_duration)

import matplotlib.pyplot as plt

# Yaş gruplarını tanımlama
conditions = [
    (data['Age'] < 18),  # 18 yaşından küçükler
    (data['Age'] >= 18) & (data['Age'] <= 65),  # 18-65 yaş arası
    (data['Age'] > 65)  # 65 yaşından büyükler
]

# Her yaş grubu için uygun ödeme durumu etiketleri
payment_labels = ['Destek Gerekli (18 Yaş Altı)', 'Kendi Ödeyecek (18-65 Yaş)', 'Destek Gerekli (65+ Yaş)']

# Yeni bir sütun oluşturarak ödeme durumunu belirleme
data['Payment Status'] = pd.cut(data['Age'], bins=[0, 18, 65, float('inf')], labels=payment_labels)

# Her kategorideki hasta sayısını hesaplama
payment_distribution = data['Payment Status'].value_counts()

# Pasta grafiği çizimi
payment_distribution.plot(kind='pie', autopct='%1.1f%%', figsize=(8, 8), startangle=90)
plt.title('Tedavi Ücretleri için Ödeme Durumu Dağılımı')
plt.ylabel('')  # Y ekseni etiketini kaldırıyoruz
plt.show()

"""
Açıklamalar:
pd.cut() fonksiyonu ile yaşlara göre üç ayrı kategori (18'den küçükler, 18-65 yaş arası ve 65+ yaş) oluşturuluyor ve bunlar "Payment Status" sütununda etiketleniyor.
value_counts() ile her bir kategori için kaç hasta olduğunu sayıyoruz.
Son olarak, plot(kind='pie') ile bu kategorilerin pasta grafiğini oluşturuyoruz.
---

"""

# Cinsiyete göre fatura miktarlarını inceleyelim
gender_billing = data.groupby('Gender')['Billing Amount'].mean()

# Grafiği çizelim
gender_billing.plot(kind='bar', figsize=(8, 6))
plt.title('Cinsiyete Göre Ortalama Fatura Miktarları')
plt.xlabel('Cinsiyet')
plt.ylabel('Ortalama Fatura Miktarı')
plt.show()

# Eksik değerlerin kontrolü
print(data.isnull().sum())

# Eksik verileri doldurma (örneğin, en çok tekrar eden değerle)
data['Blood Type'].fillna(data['Blood Type'].mode()[0], inplace=True)
data['Gender'].fillna(data['Gender'].mode()[0], inplace=True)
data['Age'].fillna(data['Age'].mean(), inplace=True)

# Cinsiyeti sayısal değerlere dönüştürme
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})

# Kan gruplarını sayısal değerlere dönüştürme (Label Encoding)
blood_type_mapping = {'A+': 0, 'A-': 1, 'B+': 2, 'B-': 3, 'AB+': 4, 'AB-': 5, 'O+': 6, 'O-': 7}
data['Blood Type'] = data['Blood Type'].map(blood_type_mapping)

# Giriş verileri (X) ve çıkış (y) için sütunları seçme
X = data[['Age', 'Gender', 'Blood Type', 'Admission Type']]  # Giriş verileri
y = data['Medical Condition']  # Çıkış: Hastalık

# Giriş verileri (X) ve çıkış (y) için sütunları seçme
X = data[['Age', 'Gender', 'Blood Type', 'Admission Type']]  # Giriş verileri
y = data['Medical Condition']  # Çıkış: Hastalık

# Kabul Tipini sayısal değerlere dönüştürme
X['Admission Type'] = X['Admission Type'].map({'Urgent': 0, 'Emergency': 1, 'Elective': 2})

from sklearn.model_selection import train_test_split

# Veriyi %80 eğitim, %20 test olarak bölme
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Eksik verileri doldur (ortalama ile)
X_train.fillna(X_train.mean(), inplace=True)
X_test.fillna(X_test.mean(), inplace=True)
# Eksik değer içeren satırları silme
X_train.dropna(inplace=True)
X_test.dropna(inplace=True)

# Eksik verileri ortalama ile doldur
X_train.fillna(X_train.mean(), inplace=True)
X_test.fillna(X_test.mean(), inplace=True)


print(len(X_test), len(y_test))  # Boyutların aynı olması gerekir.
print(X_test_tfidf.shape, y_test.shape)  # Satır sayıları eşit olmalı.
# Veri kümesinde eksik değer olup olmadığını kontrol edin
print(data.isnull().sum())

from sklearn.ensemble import RandomForestClassifier

# Modeli oluşturma ve eğitme
model = RandomForestClassifier(random_state=42)
#model.fit(X_train, y_train)

# Test ve tahmin veri boyutlarını kontrol edelim
print("X_test_tfidf Shape: ", X_test_tfidf.shape)
print("y_test Shape: ", y_test.shape)
print("y_pred Shape: ", y_pred.shape)  # y_pred'i yeniden oluşturduktan sonra

# Y_test ve X_test veri boyutlarının aynı olup olmadığını kontrol edelim
assert len(X_test) == len(y_test), "Test verileri boyutları tutarlı değil!"

# Eksik verileri temizleme
data.dropna(subset=['text_column_name', 'label_column_name'], inplace=True)

from sklearn.metrics import accuracy_score, classification_report

# Test verileri ile tahmin yapma
#y_pred = model.predict(X_test)

# Modelin doğruluğunu hesaplama
accuracy = accuracy_score(y_test, y_pred)
print(f"Model doğruluğu: {accuracy * 100:.2f}%")

# Sınıflandırma raporunu gösterme (precision, recall, f1-score)
print(classification_report(y_test, y_pred))

# RandomForest modelini oluştur ve eğit
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

import joblib

# Modeli kaydet
joblib.dump(model, 'disease_prediction_model.pkl')

# Veri setini pandas kullanarak yükleme.
# Bu kod, .csv formatındaki veri setini yükler ve pandas DataFrame olarak saklar.
data = pd.read_csv('healthcare_dataset.csv')

# Veri setinin ilk 5 satırını görüntüler. Bu, veri setindeki hangi sütunlarla çalışacağımızı görmek için faydalıdır.
data.head()



# 'text_column_name' ve 'label_column_name' yerine veri setinde ilgili sütun adlarını yazman gerekiyor.
# Örnek: 'texts' metinlerin olduğu sütun, 'labels' ise sınıflandırma etiketleri olacak.

texts = data['text_column_name']  # Metinlerin olduğu sütunu seçiyoruz.
labels = data['label_column_name']  # Sınıflandırma etiketlerinin olduğu sütunu seçiyoruz.

# Veriyi eğitim ve test setlerine ayırıyoruz. test_size=0.2, verinin %20'sini test seti olarak ayırır.
# random_state=42, sonuçların tekrar üretilebilir olmasını sağlar (her seferinde aynı sonuçlar elde edilir).
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

# TF-IDF kullanarak metinleri sayısal vektörlere dönüştürüyoruz.
# max_features=5000, en sık geçen 5000 kelimeyi kullanarak vektörleri oluşturur (bu sınırlandırma performans için yapılır).
vectorizer = TfidfVectorizer(max_features=5000)

# Eğitim verilerini kullanarak TF-IDF vektörlerini oluşturuyoruz (X_train'deki metinler).
X_train_tfidf = vectorizer.fit_transform(X_train)

# Test verilerini aynı TF-IDF vektörleştirici ile dönüştürüyoruz.
X_test_tfidf = vectorizer.transform(X_test)

# Logistic Regression modelini oluşturuyoruz.
model = LogisticRegression()

# Eğitim verilerimizle modeli eğitiyoruz.
model.fit(X_train_tfidf, y_train)

# Test seti üzerinde tahmin yapıyoruz.
y_pred = model.predict(X_test_tfidf)

